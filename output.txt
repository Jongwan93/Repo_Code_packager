{
  "base_path": "C:\\Users\\Jongwan\\Desktop\\projects\\Repo_Code_packager",
  "git_info": "- Commit: 3bb423a499b7ca7dacfc5f35ee88f8a342a2d8b2\n- Branch: main\n- Author: Jongwan93 <jwhur1993@gmail.com>\n- Date: Thu Oct 16 15:58:04 2025 -0400",
  "structure_tree": "\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 package-lock.json\n\u251c\u2500\u2500 package.json\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 Testfile_Folder\n    \u2502   \u2514\u2500\u2500 testfile.py\n    \u251c\u2500\u2500 content_packager.py\n    \u251c\u2500\u2500 file_utils.py\n    \u251c\u2500\u2500 git_utils.py\n    \u251c\u2500\u2500 main.py\n    \u2514\u2500\u2500 toml_utils.py",
  "file_contents": "### File: LICENSE\n\n```\nMIT License\n\nCopyright (c) 2025 Steven Hur\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n```\n\n### File: README.md\n\n```markdown\n# REPO_CODE_PACKAGER (Repository Context Packager)\n\nREPO_CODE_PACKAGER is a command-line tool (CLI) that analyzes a local Git repository and generates a single, clean text file optimized for sharing with Large Language Models (LLMs). No more manually copy-pasting files when asking ChatGPT for help with your code!\n\n## The Problem\n\nWhen developers ask LLMs for help with their code, the biggest challenge is providing enough context. Sharing snippets of code without the project's file structure, dependencies, and file relationships often leads to generic or unhelpful answers.\n\nREPO_CODE_PACKAGER solves this by packaging all the essential information about your repository into one well-structured file, helping the LLM understand your project's architecture much more effectively.\n\n## Prerequisites\n\nThis script requires **Python 3** to be installed on your system.\n\n1.  **Install Python 3**\n\n    - If you don't have Python installed, you can download it from [python.org](https://www.python.org/downloads/).\n\n2.  **Clone the Repository**\n    - Open your terminal (or Git Bash on Windows) and run the following command to download the project:\n      ```bash\n      git clone <YOUR_REPOSITORY_URL>\n      cd <YOUR_REPOSITORY_FOLDER_NAME>\n      ```\n3.  **Install Dependencies**\n\n    - This project uses third-party libraries listed in `requirements.txt`. Install them using pip:\n\n    - **On macOS / Linux:**\n      ```bash\n      pip3 install -r requirements.txt\n      ```\n    - **On Windows:**\n      ```bash\n      pip install -r requirements.txt\n      ```\n      or\n      ```bash\n      py -3 -m pip install -r requirements.txt\n      ```\n\n## Usage\n\nTo run the program, navigate to the project's root directory (the folder containing the `src` directory) and use the following commands in your terminal.\n\n### \ud83c\udf4e On macOS / Linux\n\nIt's common to use the `python3` command on macOS and Linux systems.\n\n- **Basic Usage (analyze the current directory):**\n\n  ```bash\n  python3 -m src.main .\n  ```\n\n- **Save output to a file:**\n\n  ```bash\n  python3 -m src.main . -o output.txt\n  ```\n\n- **Include only recent files and add line numbers:**\n  ```bash\n  python3 -m src.main . --recent --line-numbers\n  ```\n\n### On Windows\n\nOn Windows, you can use the `python` or `py -3` command.\n\n- **Basic Usage (analyze the current directory):**\n\n  ```bash\n  python -m src.main .\n  ```\n\n  or\n\n  ```bash\n  py -3 -m src.main .\n  ```\n\n- **Save output to a file:**\n\n  ```bash\n  python -m src.main . -o output.txt\n  ```\n\n- **Include only recent files and add line numbers:**\n  ```bash\n  python -m src.main . --recent --line-numbers\n  ```\n\n---\n\n## Key Features\n\n| positional arguments | description                                           |\n| -------------------- | ----------------------------------------------------- |\n| **paths**            | Path to the repository / files in the same repository |\n\n| options                   | description                                              |\n| ------------------------- | -------------------------------------------------------- |\n| **-h, --help**            | show this help message and exit                          |\n| **--version, -v**         | show program's version number and exit                   |\n| **--output, -o [OUTPUT]** | Output filename                                          |\n| **--tockens**             | Estimate and display the token count for the context     |\n| **--recent, -r [RECENT]** | Only include files modified within the last 7 days       |\n| **--line-number, -l**     | Include line number when displaying file content output  |\n| **--dirs-only, -d**       | Show only directory structure tree without file contents |\n\n## Set Flag in .toml Configuration file\n\nUser can set values of flag in **.repo-code-packager-config.toml** configuration file to change the default flag value.  \nNote that **.repo-code-packager-config.toml** should be in the same directory as **main.py**, and command line args can override the default values.\n\n# License\n\nThis project is licensed under the MIT License.\n\n```\n\n### File: package-lock.json\n\n```json\n{\n  \"name\": \"repo_code_packager\",\n  \"version\": \"1.0.0\",\n  \"lockfileVersion\": 3,\n  \"requires\": true,\n  \"packages\": {\n    \"\": {\n      \"name\": \"repo_code_packager\",\n      \"version\": \"1.0.0\",\n      \"license\": \"ISC\"\n    }\n  }\n}\n\n```\n\n### File: package.json\n\n```json\n{\n  \"name\": \"repo_code_packager\",\n  \"version\": \"1.0.0\",\n  \"description\": \"REPO_CODE_PACKAGER (Repository Context Packager) RepoScriber is a command-line tool (CLI) that analyzes a local Git repository and generates a single, clean text file optimized for sharing with Large Language Models (LLMs). No more manually copy-pasting files when asking ChatGPT for help with your code!\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/Jongwan93/Repo_Code_packager.git\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\",\n  \"type\": \"commonjs\",\n  \"bugs\": {\n    \"url\": \"https://github.com/Jongwan93/Repo_Code_packager/issues\"\n  },\n  \"homepage\": \"https://github.com/Jongwan93/Repo_Code_packager#readme\"\n}\n\n```\n\n### File: src\\Testfile_Folder\\testfile.py\n\n```python\nclass Solution:\n    def calPoints(self, operations):\n        stack = []\n        for c in operations:\n            if c == \"+\":\n                stack.append(stack[-1] + stack[-2])\n            elif c == \"D\":\n                stack.append(stack[-1] * 2)\n            elif c == \"C\":\n                stack.pop()\n            else:\n                stack.append(int(c))\n        return sum(stack)\n        \ndef main():\n    sol = Solution()\n    ops = [\"1\",\"2\",\"+\",\"C\",\"5\",\"D\"]\n    print(sol.calPoints(ops))\n\nif __name__ == \"__main__\":\n    main()\n\n\n# https://neetcode.io/problems/baseball-game?list=neetcode250\n```\n\n### File: src\\content_packager.py\n\n```python\nimport os\nimport sys\nimport json\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.util import ClassNotFound\n\n# create tree structure reflecting depth of file and directories\ndef create_structure_tree(file_list, base_path):\n    tree = {}\n    for file_path in file_list:\n        relative_path = os.path.relpath(file_path, base_path)\n        parts = relative_path.split(os.sep)\n\n        current_level = tree\n        for part in parts[:-1]:\n            if part not in current_level:\n                current_level[part] = {}\n            current_level = current_level[part]\n        current_level[parts[-1]] = None\n\n    def generate_tree_string(d, indent=''):\n        lines = []\n        # Sort items to make the output consistent every time.\n        items = sorted(d.items())\n        for i, (name, content) in enumerate(items):\n            is_last = i == len(items) - 1\n            prefix = '\u2514\u2500\u2500 ' if is_last else '\u251c\u2500\u2500 '\n            lines.append(f\"{indent}{prefix}{name}\")\n            if isinstance(content, dict): # If it's a directory, go one level deeper.\n                connector = '    ' if is_last else '\u2502   '\n                lines.extend(generate_tree_string(content, indent + connector))\n        return lines\n    return \"\\n\".join(generate_tree_string(tree))\n\n# gather the file contents and merge into a big string block.\ndef format_file_contents(file_list, base_path, args):\n    all_contents = []\n    total_lines = 0\n    total_chars = 0\n    MAX_FILE_SIZE_KB = 16\n    MAX_BYTES = MAX_FILE_SIZE_KB * 1024\n\n    for file_path in sorted(file_list):\n        try:\n            file_size = os.path.getsize(file_path)\n            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                relative_path = os.path.relpath(file_path, base_path)\n                all_contents.append(f\"### File: {relative_path}\")\n                \n                content = f.read()\n\n                # Lab3-1: add line numbers to the output file\n                if args.line_numbers:\n                    lines = content.splitlines()\n                    numbered_lines = [f\"{i+1}: {line}\" for i, line in enumerate(lines)]\n                    content = \"\\n\".join(numbered_lines)\n\n                if file_size > MAX_BYTES:\n                    content = content[:MAX_BYTES]\n                    truncation_note = f\"\\n... (file truncated due to size > {MAX_FILE_SIZE_KB}KB)\"\n                    content += truncation_note\n\n                lang_name = \"\"\n                try:\n                    # find the language from file name\n                    lexer = guess_lexer_for_filename(file_path, content)\n                    lang_name = lexer.aliases[0] if lexer.aliases else \"\"\n                except ClassNotFound:\n                    # if it failes to find language name\n                    pass\n\n                # Add the content inside a markdown code block.\n                all_contents.append(f\"```{lang_name}\\n{content}\\n```\")\n                \n                # Count lines for the summary later.\n                total_lines += content.count('\\n') + 1\n                total_chars += len(content)\n\n        except Exception as e:\n            print(f\"Error reading file {file_path}: {e}\", file=sys.stderr)\n    return \"\\n\\n\".join(all_contents), total_lines, total_chars\n\n# calculate entire number of files and number of lines.\ndef generate_summary(file_list, total_lines):\n    file_count = len(file_list)\n    summary_string = (\n        f\"- Total files: {file_count}\\n\"\n        f\"- Total lines: {total_lines}\"\n    )\n    return summary_string\n\ndef format_json(data):\n    # get the dictionary data and convert to json string\n    return json.dumps(data, indent=2)\n\ndef format_markdown(data):\n    # get the dictionary data and convert to markdown string\n    output_parts = [\n        f\"# Repository Context\",\n        f\"## File System Location\\n\\n{data['base_path']}\",\n        f\"## Git Info\\n\\n{data['git_info']}\",\n        f\"## Structure\\n\\n{data['structure_tree']}\",\n        f\"## File Contents\\n\\n{data['file_contents']}\",\n        f\"## Summary\\n\\n{data['summary']}\"\n    ]\n    return \"\\n\\n\".join(output_parts)\n```\n\n### File: src\\file_utils.py\n\n```python\nimport os\nimport time\n\n# find the files and directory\n# Issue #2 Fix: Return absolute paths [9/14/2025]\ndef get_all_files(paths, exclude_dirs=None):\n    all_files = []\n    excluded_set = set(exclude_dirs) if exclude_dirs else set()\n\n    for path in paths:\n        # Convert the input path to an absolute path\n        abs_path = os.path.abspath(path)\n        # if the path leads to file, add it to list\n        if os.path.isfile(abs_path):\n            if not os.path.basename(abs_path).startswith('.'):\n                all_files.append(abs_path)\n        # if the path is directory, add all the files under it\n        elif os.path.isdir(abs_path):\n            for root, dirs, files in os.walk(abs_path):\n                dirs[:] = [d for d in dirs if not d.startswith('.') and d not in excluded_set]\n                for file in files:\n                    if not file.startswith('.'):\n                        all_files.append(os.path.join(root, file))\n    return all_files\n\n# check if a file was modified recently\ndef is_recently_modified(file_path, days=7):\n    try:\n        last_modified = os.path.getmtime(file_path)\n        now = time.time()\n        return (now - last_modified) <= days * 86400\n    except FileNotFoundError:\n        return False\n```\n\n### File: src\\git_utils.py\n\n```python\nimport subprocess\n\ndef get_git_info(repo_path):\n    try:\n        # %H: commit hash, %d: branch info, %an: author name, %ae: author email, %ad: date, %n: newline\n        git_format = \"%H%n%d%n%an <%ae>%n%ad\"\n        \n        # execute git log command to get the latest commit info\n        full_output = subprocess.check_output(\n            ['git', 'log', '-1', f'--pretty=format:{git_format}'],\n            cwd=repo_path, text=True, stderr=subprocess.PIPE\n        ).strip()\n\n        # new line is the delimiter\n        lines = full_output.split('\\n')\n        \n        commit = lines[0]\n        branch_line = lines[1]\n        author = lines[2]\n        date = lines[3]\n\n        # Parse branch name - extract 'main'\n        if '->' in branch_line:\n            branch = branch_line.split('->')[1].split(',')[0].strip()\n        else:\n            branch = \"detached HEAD\"\n\n        return (\n            f\"- Commit: {commit}\\n\"\n            f\"- Branch: {branch}\\n\"\n            f\"- Author: {author}\\n\"\n            f\"- Date: {date}\"\n        )\n    \n    except (subprocess.CalledProcessError, FileNotFoundError, IndexError):\n        return \"Not a git repository\"\n```\n\n### File: src\\main.py\n\n```python\nimport argparse\nimport sys\nimport os\nimport time\nfrom file_utils import get_all_files, is_recently_modified\nfrom git_utils import get_git_info\nfrom content_packager import create_structure_tree, format_file_contents, generate_summary, format_json, format_markdown\nfrom toml_utils import load_config\n\nTOOL_VERSION = \"0.1.0\"\n\ndef build_report(base_path, git_info, structure_tree, file_contents, summary, file_list, args):\n    output_parts = [\n        f\"# Repository Context\\n\\n## File System Location\\n\\n{base_path}\",\n        f\"## Git Info\\n\\n{git_info}\",\n        f\"## Structure\\n\\n{structure_tree}\"\n    ]\n    \n    if not args.dirs_only:\n        output_parts.append(f\"## File Contents\\n\\n{file_contents}\")\n\n    # 'recent_summary' section\n    if args.recent:\n        recent_summary = \"\\n## Recent Changes\\n\"\n        if file_list:\n            for f in file_list:\n                days_ago = int((time.time() - os.path.getmtime(f)) // 86400)\n                recent_summary += f\"- {os.path.basename(f)} (modified {days_ago} days ago)\\n\"\n        else:\n            recent_summary += \"No files modified in the last 7 days.\\n\"\n        output_parts.append(recent_summary)\n\n    output_parts.append(f\"## Summary\\n\\n{summary}\")\n    \n    return \"\\n\\n\".join(output_parts)\n\ndef main():\n    # ArgumentParser object creation\n    parser = argparse.ArgumentParser(\n        description=\"Repository Context Packager\"\n    )\n\n    parser.add_argument(\n        \"-v\", \"--version\",\n        action = \"version\",\n        version = f\"%(prog)s {TOOL_VERSION}\"\n    )\n\n    # file or directory argument\n    parser.add_argument(\n        \"paths\",\n        nargs = \"+\", # 1 or more\n        help = \"Paths to files or directories to include in the context.\"\n    )\n\n    # optional feature 1: Output to file\n    parser.add_argument(\n        \"-o\", \"--output\",\n        help = \"Path to the output file. If not specified, prints to standard output.\"\n    )\n\n    # optional feature 2: Token counting\n    parser.add_argument(\n        \"--tokens\",\n        action = \"store_true\", #This makes it a flag, like --version\n        help = \"Estimate and display the token count for the context.\"\n    )\n    \n    # includes files modified within 7 days\n    parser.add_argument(\n        \"-r\", \"--recent\",\n        action=\"store_true\",\n        help=\"Only include files modified within the last 7 days\"\n    )\n    \n    # Lab3-1: adds line numbers to the output file\n    parser.add_argument(\n        \"-l\", \"--line-numbers\",\n        action=\"store_true\",\n        help=\"Include line numbers in the file content output.\"\n    )\n\n    # Lab3-2: create directory tree structure\n    parser.add_argument(\n        \"-d\", \"--dirs-only\",\n        action=\"store_true\",\n        help=\"Show only the directory structure without file contents.\"\n    )\n\n    # Lab6: output format style\n    parser.add_argument(\n        \"--style\",\n        default=\"markdown\",\n        choices=[\"markdown\", \"json\"],\n        help=\"The output format (markdown or json).\"\n    )\n\n    #load default values from .toml config\n    try:\n        defaults = load_config(\".repo-code-packager-config.toml\")\n    except RuntimeError as e:\n        sys.exit(f\"Runtime Error: {e}\")\n    \n    # find exclude_dirs. if not found, set to empty list\n    exclude_list = []\n    if defaults:\n        exclude_list = defaults.pop(\"exclude_dirs\", [])\n        parser.set_defaults(**defaults)\n\n    # pare the argument\n    args = parser.parse_args()\n\n    print(f\"DEBUG: Files to ignore: {exclude_list}\")\n\n    first_path_abs = os.path.abspath(args.paths[0])\n    base_path = os.path.dirname(first_path_abs) if os.path.isfile(first_path_abs) else first_path_abs\n\n    # get all the files from provided path\n    file_list = get_all_files(args.paths, exclude_list)\n\n    if args.recent:\n        file_list = [f for f in file_list if is_recently_modified(f)]\n\n    if not file_list:\n        print(\"Error: No files found in the specified paths.\", file=sys.stderr)\n        sys.exit(1)\n\n    git_info_str = get_git_info(base_path)\n    structure_tree_str = create_structure_tree(file_list, base_path)\n    file_contents_str, total_lines, total_chars = format_file_contents(file_list, base_path, args)\n    summary_str = generate_summary(file_list, total_lines)\n\n    report_data = {\n        \"base_path\": base_path,\n        \"git_info\": git_info_str,\n        \"structure_tree\": structure_tree_str,\n        \"file_contents\": file_contents_str,\n        \"summary\": summary_str\n    }\n\n    final_output = \"\"\n    if args.style == 'json':\n        final_output = format_json(report_data)\n    else:\n        final_output = format_markdown(report_data)\n\n    # optional feature 2: Token counting\n    if args.tokens:\n        estimated_tokens = total_chars // 4\n        print(f\"Estimated tokens: {estimated_tokens}\", file=sys.stderr)\n\n    # optional feature 1: Output to file\n    if args.output:\n        try:\n            with open(args.output, 'w', encoding='utf-8') as f:\n                f.write(final_output.strip())\n            print(f\"Context successfully written to {args.output}\", file=sys.stderr)\n        except IOError as e:\n            print(f\"Error writing to file {args.output}: {e}\", file=sys.stderr)\n            sys.exit(1)\n    else:\n        print(final_output.strip())\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### File: src\\toml_utils.py\n\n```python\nimport tomllib\nimport os\n\ndef load_config(file_path=\".repo-code-packager-config.toml\"):\n    if not os.path.exists(file_path):\n        return\n\n    try:\n        with open(file_path, \"rb\") as f:\n            return tomllib.load(f)\n    except:\n        raise RuntimeError(f'Cannot parse config file \"{file_path}\" as TOML')\n    \n```",
  "summary": "- Total files: 10\n- Total lines: 555"
}